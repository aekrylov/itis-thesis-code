{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation\n",
    "\n",
    "\n",
    "This is an example of applying :class:`sklearn.decomposition.NMF` and\n",
    ":class:`sklearn.decomposition.LatentDirichletAllocation` on a corpus\n",
    "of documents and extract additive models of the topic structure of the\n",
    "corpus.  The output is a list of topics, each represented as a list of\n",
    "terms (weights are not shown).\n",
    "\n",
    "Non-negative Matrix Factorization is applied with two different objective\n",
    "functions: the Frobenius norm, and the generalized Kullback-Leibler divergence.\n",
    "The latter is equivalent to Probabilistic Latent Semantic Indexing.\n",
    "\n",
    "The default parameters (n_samples / n_features / n_components) should make\n",
    "the example runnable in a couple of tens of seconds. You can try to\n",
    "increase the dimensions of the problem, but be aware that the time\n",
    "complexity is polynomial in NMF. In LDA, the time complexity is\n",
    "proportional to (n_samples * iterations).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "done in 67.991s.\n"
     ]
    }
   ],
   "source": [
    "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Lars Buitinck\n",
    "#         Chyi-Kwei Yau <chyikwei.yau@gmail.com>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "from text_processing.simple import parse\n",
    "\n",
    "n_samples = 5000\n",
    "n_features = 5000\n",
    "n_components = 15\n",
    "n_top_words = 20\n",
    "\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "data_samples = [parse(f) for f in itertools.islice(Path(\"./out/docs_simple2\").rglob(\"*.html\"), n_samples)]\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for NMF...\n",
      "done in 14.790s.\n",
      "Extracting tf features for LDA...\n",
      "done in 10.938s.\n",
      "\n",
      "Fitting the NMF model (Frobenius norm) with tf-idf features, n_samples=5000 and n_features=5000...\n",
      "done in 16.480s.\n",
      "\n",
      "Topics in NMF model (Frobenius norm):\n",
      "Topic #0: товар покупател поставк договор ответчик поставщик оплат sum 2017 требован ил соответств накладн поставлен сумм истц товарн обязательств сторон продукц\n",
      "Topic #1: энерг электрическ теплов потреблен оплат потребител абонент мощност договор ответчик организац сет энергоснабжен электроэнерг фактическ теплоснабжен 2017 прибор соответств теплоносител\n",
      "Topic #2: арендн аренд плат договор арендатор арендодател ответчик имуществ пользован внесен помещен 2017 платеж 01 требован соответств sum задолжен услов размер\n",
      "Topic #3: страхов транспортн возмещен страховщик страхован выплат потерпевш вред экспертиз поврежден расход средств осаг причинен автомобил дтп прав обязательн ремонт восстановительн\n",
      "Topic #4: приказ 229 взыскател выдач arbitr огрн ru 2018 област алтайск ул www кра нем inf http тел ma сведен рассмотрел\n",
      "Topic #5: работ выполнен подрядчик заказчик договор подряд приемк кс результат выполн акт ответчик sum сдач сторон стоимост документац субподрядчик строительн недостатк\n",
      "Topic #6: дом многоквартирн помещен коммунальн собственник жил содержан общ имуществ услуг жилищн управля управлен общедомов ремонт организац нежил плат жк ресурсоснабжа\n",
      "Topic #7: контракт муниципальн заказчик исполнен государствен подрядчик обязательств пен поставщик нужд исполнител 44 учрежден работ 2017 штраф предусмотрен контрактн товар пункт\n",
      "Topic #8: земельн участк кадастров прав собствен участок объект недвижим площад номер администрац здан муниципальн кв строительств государствен земл регистрац лиц район\n",
      "Topic #9: саморегулируем взнос член членск организац ассоциац некоммерческ сро регулярн членств партнерств союз фонд компенсацион собран единовремен объединен поступлен строител устав\n",
      "Topic #10: услуг ответчик договор требован лиц истц соответств 2017 оплат оказа что сторон sum ил котор оказан исков оо расход доказательств\n",
      "Topic #11: вагон груз железнодорожн перевозк перевозчик транспорт транспортн станц дорог доставк грузополучател грузов ржд автомобильн накладн грузоотправител пут устав масс контейнер\n",
      "Topic #12: неустойк обязательств размер нарушен пен 333 несоразмерн просрочк ден исполнен сумм ответчик последств оплат кредитор уплат срок договор снижен sum\n",
      "Topic #13: процент средств денежн чуж пользован займ неосновательн 395 сумм заемщик sum обогащен возврат ответчик размер требован период 2016 банк договор\n",
      "Topic #14: хакас приказ республик абака 229 655017 тысяч огрн 2018 крылов руб учрежден нахожден дня ул выдач бюджетн муниципальн http khakas\n",
      "\n",
      "Fitting the NMF model (generalized Kullback-Leibler divergence) with tf-idf features, n_samples=5000 and n_features=5000...\n",
      "done in 71.798s.\n",
      "\n",
      "Topics in NMF model (generalized Kullback-Leibler divergence):\n",
      "Topic #0: что услов удовлетворен требован част указа сторон явля сумм соответств 167 2017 эт со согласн договор ответчик установлен срок уплат\n",
      "Topic #1: энерг энергоснабжен фактическ услуг учет через фз 539 абонент федеральн сет энергоснабжа 544 теплов фактур уплат энергетическ присоединен электрическ соблюда\n",
      "Topic #2: размер аренд участк расположен арендатор числ 01 16 своевремен кв владен управлен арендн пункт имуществ плат эксплуатац арендодател внесен эт\n",
      "Topic #3: причинен применен причин произошл предел автомобил убытк происшеств страхов потерпевш вред произвест результат выплат принят произвел транспортн страхован производств страховщик\n",
      "Topic #4: ул состав сведен приложен огрн приказ 2018 учрежден рассмотрел ru тел 229 arbitr обществ факс http ответствен имен сумм нем\n",
      "Topic #5: заказчик выполнен задан выполн подрядчик подряд этап объект сдач приемк строительств 702 строительн результат работ документац техническ 711 цен е\n",
      "Topic #6: управлен собственник управля содержан ул дом утвержден жил решен многоквартирн жилищн услуг том согласн так указа такж собран помещен удовлетворен\n",
      "Topic #7: пен штраф товар осуществля переда поставщик ден частност 330 покупател цел поставлен 506 форм отдельн общ поставк обеспечен подобн одн\n",
      "Topic #8: трет участ то цел 170 17 ход 167 самостоятельн результат характер существен документ предмет том чем 19 25 интерес 2015\n",
      "Topic #9: юридическ явля федеральн яв фз такж тем так том эт участник установл требован спор соответств случа указа тог что совершен\n",
      "Topic #10: оказан оказа услуг возмездн 779 781 оказыва исполнител адвокат заказчик юридическ чрезмерн задан 106 вниман взыскива верховн осуществ акт баланс\n",
      "Topic #11: явн убытк уменьш 333 несоразмерн уменьшен снижен соразмерн 330 некотор верховн неустойк возможн осуществлен способ тольк выгод ненадлежа значительн 81\n",
      "Topic #12: транспортн сторон транспорт указыва след состав составлен счита счет согласн сет территор учет спорн груз ссыла электрон составля товарн техническ\n",
      "Topic #13: чуж процент средств размер пользован уклонен удержан счет возврат 395 период росс сделк уплат сбережен банк ставк сумм неправомерн денежн\n",
      "Topic #14: течен учрежден уплачен федеральн через тысяч срок сил средств со республик явля руб превыша такж сибирск поступ хакас пода поручен\n",
      "\n",
      "Fitting LDA models with tf features, n_samples=5000 and n_features=5000...\n",
      "done in 86.379s.\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: работ выполнен договор заказчик ответчик подрядчик акт 2017 sum истц сторон что требован пункт соответств сумм приемк 2016 оплат результат\n",
      "Topic #1: груз вагон железнодорожн пут общ перевозк пользован перевозчик транспортн транспорт акт ответчик станц при соответств плат дорог что ил доставк\n",
      "Topic #2: убытк что был при ответчик для котор ил нарушен акт ремонт качеств причин ег лиц недостатк требован истц соответств работ\n",
      "Topic #3: дом помещен многоквартирн коммунальн услуг общ собственник жил имуществ содержан организац управлен ответчик прав управля соответств договор жилищн плат учет\n",
      "Topic #4: контракт обязательств организац исполнен закон государствен соответств взнос пен саморегулируем член размер муниципальн уплат пункт 2017 предусмотрен заказчик ил фз\n",
      "Topic #5: энерг оплат договор ответчик электрическ 2017 соответств закон требован ил истц теплов потреблен период фактическ sum потребител учет обязательств сумм\n",
      "Topic #6: 2018 огрн год област обществ приказ ул республик решен 229 ru ограничен arbitr ответствен государствен sum 2017 кра учрежден имен\n",
      "Topic #7: договор неустойк обязательств размер ответчик требован сумм соответств нарушен sum исполнен пункт ил срок уплат истц что сторон услов кредитор\n",
      "Topic #8: страхов возмещен транспортн расход средств требован размер выплат прав sum котор вред закон страхован лиц потерпевш ответчик ил об ответствен\n",
      "Topic #9: договор 2016 2015 оо sum 2017 10 12 01 11 2014 сумм 06 09 год 07 исков 03 04 05\n",
      "Topic #10: ответчик договор товар требован sum 2017 оплат истц соответств ил сумм обязательств сторон поставк покупател размер котор исков доказательств услов\n",
      "Topic #11: договор муниципальн закон ил строительств соответств заключен государствен лесн для пункт част услов требован федеральн сторон изменен прав при объект\n",
      "Topic #12: услуг лиц расход прав что юридическ котор истц ответчик требован представител ил доказательств при соответств из оплат рассмотрен закон пункт\n",
      "Topic #13: земельн участк прав аренд имуществ государствен собствен лиц обществ закон арендн плат что договор соответств ил объект котор требован област\n",
      "Topic #14: договор вод присоединен водоотведен организац объект водоснабжен ответчик технологическ пункт тариф соответств сет прав при услуг сточн для что хозяйств\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "\n",
    "class key_dependent_dict(defaultdict):\n",
    "    def __init__(self,f_of_x):\n",
    "        super().__init__(None) # base class doesn't get a factory\n",
    "        self.f_of_x = f_of_x # save f(x)\n",
    "    def __missing__(self, key): # called when a default needed\n",
    "        ret = self.f_of_x(key) # calculate default value\n",
    "        self[key] = ret # and install it in the dict\n",
    "        return ret\n",
    "\n",
    "\n",
    "STOP_WORDS = {'от', 'на', 'не', 'рф', 'ст'}\n",
    "\n",
    "stemmer = SnowballStemmer(\"russian\")\n",
    "CACHE = key_dependent_dict(lambda w: stemmer.stem(w))\n",
    "\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([CACHE[w] for w in analyzer(doc) if w not in STOP_WORDS])\n",
    "\n",
    "\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedTfidfVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([CACHE[w] for w in analyzer(doc) if w not in STOP_WORDS])\n",
    "\n",
    "\n",
    "# Use tf-idf features for NMF.\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = StemmedTfidfVectorizer(max_df=0.9, min_df=0.01,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words=None)\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = StemmedCountVectorizer(max_df=0.9, min_df=0.01,\n",
    "                                max_features=n_features,\n",
    "                                stop_words=None)\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (Frobenius norm) with tf-idf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model (Frobenius norm):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)\n",
    "\n",
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (generalized Kullback-Leibler divergence) with \"\n",
    "      \"tf-idf features, n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
    "          l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)\n",
    "\n",
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
